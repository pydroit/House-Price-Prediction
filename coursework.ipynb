{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b286c1c-12ec-4ed1-b678-077c8145dbaf",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## _Real Estate Price Prediction Using Machine Learning_\n",
    "\n",
    "### Dataset Description \n",
    "\n",
    "> This data set contains 2,226,382 house listings. The dataset used for this coursework is a data of real estate listings in the United States of America (USA). The data was gotten from, and is hosted on [Kaggle](https://www.kaggle.com/datasets/ahmedshahriarsakib/usa-real-estate-dataset/data) while the static dataset hosted on google drive and used throughout this project is found [here](https://drive.usercontent.google.com/download?id=1wBJmx7yGbrjRFdSZOp11PkfPfC3e4NNG&export=download&confirm=%7b%7bVALUE%7d%7d)\n",
    "\n",
    "> This study aims at developing a Machine Learning model that predicts the price of houses. \n",
    "> A quick overview of the dataset shows there are **12** Columns: \n",
    "`['brokered_by', 'status', 'price', 'bed', 'bath', 'acre_lot', 'street', 'city', 'state', 'zip_code', 'house_size', 'prev_sold_date']`\n",
    " \n",
    " > The `'price'` column is the target feature for our supervised learning\n",
    "\n",
    "\n",
    "\n",
    "### Questions we aim to answer with this study\n",
    "1. What regression models perform best in the prediction of real estate price?\n",
    "2. What impact will ensemble and hyperparameter tuning have?\n",
    "3. What features have the most impact on prediction accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cf732b-0e01-4bbc-87b7-24088babc34f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "\n",
    "## Data Analysis, Statistics and Visualization Libraries\n",
    "import pandas as pd # Data manipulation\n",
    "import numpy as np # Numerical operations and array manipulation\n",
    "import matplotlib.pyplot as plt # Creating visualizations\n",
    "import seaborn as sns # Creative graphical illustrations built on top of matplotlib\n",
    "import plotly.express as px # Graph\n",
    "import plotly.graph_objects as go #Graph\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.anova import anova_lm # Anova\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "\n",
    "\n",
    "## Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split # To split data into training and testing sets\n",
    "from sklearn.preprocessing import StandardScaler # Helps standardize features by removing the mean and scaling to unit variance\n",
    "from sklearn.tree import DecisionTreeRegressor # Constructs decision tree-based regression models\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor # Ensemble method based on decision trees for regression tasks\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, confusion_matrix, classification_report, accuracy_score # Calculates performance and accuracy scores\n",
    "from sklearn.preprocessing import OneHotEncoder # Used for One-Hot Encoding\n",
    "import category_encoders as ce # Used for Target Encoding\n",
    "from category_encoders import MEstimateEncoder # Used for Target Encoding\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, KBinsDiscretizer # Used for normalization and Z-normalization (standardization)\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, ElasticNetCV, Lasso, Ridge,  LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825bb64f-c49d-4fa7-98f7-cee10b5c4ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c32c76-41d2-4238-a39b-ec54b690ca22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download and load dataset from googledrive direct download link\n",
    "data_url = 'https://drive.usercontent.google.com/download?id=1wBJmx7yGbrjRFdSZOp11PkfPfC3e4NNG&export=download&confirm={{VALUE}}'\n",
    "data_original = pd.read_csv(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce1037-0cf4-40b9-bcf6-918e8c6e78c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the column names\n",
    "print(list(data_original.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe717eb2-b4f1-4808-943f-5ec2b250ddaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate a copy of the original data, and place the 'price' column at the end as it is the target variable for the supervised learning\n",
    "data = data_original[['status', 'bed', 'bath', 'acre_lot', 'city', 'state', 'zip_code', 'house_size', 'prev_sold_date', 'brokered_by', 'street', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d60e1-2375-439e-b70c-00c14e5ad3e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Shape of the data\n",
    "print(f'The data has {data.shape[0]} rows and {data.shape[1]} features\\n')\n",
    "print('#'*50)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f52ad68-c14b-490b-8acf-4c05cd8c6e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preview of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f92838-dd6d-46b6-bc2c-01b77d13cd6f",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "> Data is checked for consistency and accuracy. Appropriate actions are taken to clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd79654b-cc04-4e77-96fd-035a8a53b335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check 1: Check for duplicates\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7470c04-7c86-4412-8cf8-c20a2722dd32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check 2: Check for null/missing values\n",
    "print('Missing Values Count')\n",
    "print('*'*50)\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc73d86-95fe-4b63-822a-620039249fd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Samples of data with missing values in the 'price' column\n",
    "data[data['price'].isna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2670344e-327b-4387-b043-2838d109efa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Treating missing Values 1:\n",
    "# Drop missing values in the 'price' field\n",
    "\n",
    "data.dropna(subset = ['price', 'zip_code', 'city', 'state'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957e77ab-a5e2-4e51-95a5-3552f082b30f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Treating missing Values 2:\n",
    "# Replacing filled values with 'Yes' and missing values with 'No' in the 'prev_sold' feature\n",
    "#Creating new column to encode 'Yes' as 1 and 'No' as 0\n",
    "\n",
    "data.rename(columns={'prev_sold_date': 'prev_sold'}, inplace=True)\n",
    "data['prev_sold'] = data['prev_sold'].apply(lambda x: 'Yes' if pd.notna(x) else 'No')\n",
    "\n",
    "data['prev_sold_enc'] = data['prev_sold'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818bdcf7-304a-435b-884a-588d649288b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Treating missing Values 3:\n",
    "# Replace missing values in the numerical fields\n",
    "\n",
    "data['bed'].fillna(data['bed'].mode()[0], inplace=True)\n",
    "data['bath'].fillna(data['bath'].mode()[0], inplace=True)\n",
    "data['acre_lot'].fillna(data['acre_lot'].mode()[0], inplace=True)\n",
    "data['house_size'].fillna(data['house_size'].mode()[0], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e7737-d596-4b56-a4ad-9641a277b0e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Confirm treating of missing values is successful\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2012dfa5-9861-4a5a-9441-dd5044bc200b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Outlier Validation\n",
    "\n",
    "fig, axis = plt.subplots(2, 3, figsize=(15, 7))\n",
    "\n",
    "axis[0, 0].boxplot(data['price'])\n",
    "axis[0, 0].set_title('Price')\n",
    "\n",
    "axis[0, 1].boxplot(data['bed'])\n",
    "axis[0, 1].set_title('Bedrooms')\n",
    "\n",
    "axis[0, 2].boxplot(data['bath'])\n",
    "axis[0, 2].set_title('Bathrooms')\n",
    "\n",
    "axis[1, 0].boxplot(data['acre_lot'])\n",
    "axis[1, 0].set_title('Acres')\n",
    "\n",
    "axis[1, 1].boxplot(data['house_size'])\n",
    "axis[1, 1].set_title('House size');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb68b491-00b9-4da1-8355-fe5fafbc3794",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove outliers that are outside 1.5 times the interquartile range below and above the lower and upper quartiles respectively\n",
    "\n",
    "outlier_columns = ['price', 'bed', 'bath', 'acre_lot', 'house_size' ] #numerical columns where outliers are to be removed\n",
    "quart_1 = data[outlier_columns].quantile(0.25)\n",
    "quart_3 = data[outlier_columns].quantile(0.85)\n",
    "IQR = quart_3 - quart_1 #Interquartile Range\n",
    "\n",
    "data = data[~((data[outlier_columns] < (quart_1 - 1.5 * IQR)) | (data[outlier_columns] > (quart_3 + 1.5 * IQR))).any(axis=1)]\n",
    "data = data[data['price']>=100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb63226-b4d2-439a-a902-5f3a8cfdd7a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Outlier Validation After outliers have been removed\n",
    "fig, axis = plt.subplots(2, 3, figsize=(15, 7))\n",
    "\n",
    "axis[0, 0].boxplot(data['price'])\n",
    "axis[0, 0].set_title('Price')\n",
    "\n",
    "axis[0, 1].boxplot(data['bed'])\n",
    "axis[0, 1].set_title('Bedrooms')\n",
    "\n",
    "axis[0, 2].boxplot(data['bath'])\n",
    "axis[0, 2].set_title('Bathrooms')\n",
    "\n",
    "axis[1, 0].boxplot(data['acre_lot'])\n",
    "axis[1, 0].set_title('Acres')\n",
    "\n",
    "axis[1, 1].boxplot(data['house_size'])\n",
    "axis[1, 1].set_title('House size');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2837a3c5-874a-4f1e-b47e-8a46ad07d586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# States in the dataset but are not in the US\n",
    "states_in_us = ['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming', 'District of Columbia', 'American Samoa', 'Guam', 'Northern Mariana Islands', 'Puerto Rico', 'United States Minor Outlying Islands', 'Virgin Islands']\n",
    "states_in_dataset = list(data['state'].unique())\n",
    "\n",
    "diff = [x for x in states_in_us + states_in_dataset if x not in states_in_us]\n",
    "\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c7d69-216e-4576-a115-a0f7df2db006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Remove non-US state from data\n",
    "\n",
    "# data = data[data['state']!='New Brunswick']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d14af8-54c6-48c6-b3e5-d43859979e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove ‘brokered_by’ and ‘street’ columns\n",
    "\n",
    "data = data[['status', 'bed', 'bath', 'acre_lot', 'city', 'state', 'zip_code', 'house_size', 'prev_sold', 'prev_sold_enc', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142a6449-8360-4553-a30a-b9755d58a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert zip code data type to nominal\n",
    "\n",
    "data['zip_code'] = data['zip_code'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f25309a-ce7c-46a1-8130-3fed98ba6cde",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis \n",
    "\n",
    "> After the data has been cleaned, we now gain some insights from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546172fb-f789-4937-9dbb-b599b8683954",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Shape of the data\n",
    "print(f'The data has {data.shape[0]} rows and {data.shape[1]} features\\n')\n",
    "print('#'*50)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7622371-f76d-4ebd-bf01-0d5e747e1b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a567129f-0f25-4ebd-afe2-e1eb992eed81",
   "metadata": {
    "tags": []
   },
   "source": [
    "> Code to display dataframes side by side\n",
    "> Reference and acknowledgement: Liu Zuo Lin on [Medium](https://python.plainenglish.io/displaying-multiple-dataframes-side-by-side-in-jupyter-lab-notebook-9a4649a4940)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a275e3-73fb-4dc4-b25a-2b090013bc2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to display DataFrames side by side\n",
    "\n",
    "def side_by_side(*dfs):\n",
    "    html = '<div style=\"display:flex\">'\n",
    "    for df in dfs:\n",
    "        html += '<div style=\"margin-right: 2em\">'\n",
    "        html += df.to_html()\n",
    "        html += '</div>'\n",
    "    html += '</div>'\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c3d0eb-9f68-44af-832a-cd0d1d0b9c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Describe the data to show mean, minimum, maximum etc.\n",
    "# Format output to 2 decimal places for readability\n",
    "describe_num_a = data.describe().T.applymap(lambda x: f\"{x:,.2f}\")\n",
    "describe_obj_b = data.describe(include = 'object').T\n",
    "\n",
    "side_by_side(describe_num_a, describe_obj_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6bf7cf-2ade-4a74-bf75-8dde81c1d25e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize distribution in each numerical column\n",
    "# visualize outliers in each numerical column\n",
    "\n",
    "fig, axis = plt.subplots(2, 3, figsize=(15, 7))\n",
    "\n",
    "axis[0, 0].hist(data['price'])\n",
    "axis[0, 0].set_title('Price')\n",
    "axis[0, 0].set_ylabel('Count')\n",
    "\n",
    "axis[0, 1].hist(data['bed'], range=(0,10))\n",
    "axis[0, 1].set_title('Bedroom')\n",
    "\n",
    "axis[0, 2].hist(data['bath'], range=(0,10))\n",
    "axis[0, 2].set_title('Bathroom')\n",
    "\n",
    "axis[1, 0].hist(data['acre_lot'])\n",
    "axis[1, 0].set_title('Acres')\n",
    "axis[1, 0].set_ylabel('Count')\n",
    "\n",
    "axis[1, 1].hist(data['house_size'])\n",
    "axis[1, 1].set_title('House Size')\n",
    "\n",
    "axis[1, 2].hist(data['prev_sold_enc'], range=(0,1), bins=2)\n",
    "axis[1, 2].set_title('Previously Sold');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0983f59e-9a33-41a3-9322-5fb94c9617f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Computation of a standard correlation coefficient between every attribute pair\n",
    "\n",
    "corr_matrix = data.corr(numeric_only=True)\n",
    "\n",
    "clustermap_corr = sns.clustermap(corr_matrix, annot=True, cmap='crest', figsize=(10, 4.5))\n",
    "\n",
    "# How each attribute correlate with price\n",
    "print(f'How each attribute correlate with price')\n",
    "print('-'*50)\n",
    "print(corr_matrix['price'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf7afc6-a70d-4817-b905-f64d65f554f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Price Distribution\n",
    "\n",
    "# fig = px.histogram(data, x=\"price\", nbins=30, template=\"plotly\", width=900, height=500)\n",
    "# fig.update_layout(title=\"Price Distribution\", xaxis_title=\"House Price\", yaxis_title=\"House Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba99934e-4363-4154-95ef-a3386928688f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Distribution of Price by Bed\n",
    "\n",
    "fig1 = px.histogram(data, x=\"price\", color=\"bed\", nbins=30, width=900, height=340, \n",
    "                   color_discrete_sequence=px.colors.qualitative.Light24)\n",
    "\n",
    "fig2 = px.histogram(data, x=\"price\", color=\"bath\", nbins=30, width=900, height=340, \n",
    "                   color_discrete_sequence=px.colors.qualitative.Light24)\n",
    "\n",
    "fig1.update_layout(title=\"Distribution of Price by Bed\", xaxis_title=\"Price\", yaxis_title=\"Count\")\n",
    "fig2.update_layout(title=\"Distribution of Price by Bath\", xaxis_title=\"Price\", yaxis_title=\"Count\")\n",
    "\n",
    "fig1.show()\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e311828-6ef4-4e50-adb7-591e89b4005c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_price_bed = data.groupby('bed', as_index=False).agg({'price' : 'mean'}).sort_values('price', ascending=False)\n",
    "mean_price_bath = data.groupby('bath', as_index=False).agg({'price' : 'mean'}).sort_values('price', ascending=False)\n",
    "print('Distribution of Bed and Bath by Mean Price')\n",
    "side_by_side(mean_price_bed, mean_price_bath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ba42ee-7415-484b-b7a5-ee17fe52c186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['bed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f4d464-9bfa-47b7-86b5-dfe98a2da3d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One-Way ANOVA to see relationship between price and number of bedrooms\n",
    "\n",
    "print('One-Way ANOVA to see relationship between price and number of bedrooms')\n",
    "print('*'*70)\n",
    "two_bed = data.loc[data[\"bed\"] == 2.0, \"price\"]\n",
    "three_bed = data.loc[data[\"bed\"] == 3.0, \"price\"]\n",
    "four_bed = data.loc[data[\"bed\"] == 4.0, \"price\"]\n",
    "five_bed = data.loc[data[\"bed\"] == 5.0, \"price\"]\n",
    "f_oneway(two_bed,three_bed,four_bed,five_bed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4575af7-d2ad-4fc1-90c3-4a6432d7b8a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Two-Way ANOVA to see relationship between price and other numeric features\n",
    "\n",
    "formula = \"price ~ bed + bath + acre_lot + prev_sold_enc + house_size\"\n",
    "model = ols(formula,data = data).fit()\n",
    "anova_result = sm.stats.anova_lm(model, type=2)\n",
    "print('Two-Way ANOVA to see relationship between price and other numeric features')\n",
    "print('*'*70)\n",
    "anova_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebb85f1-9ab9-475a-9c4a-349eab05a807",
   "metadata": {},
   "source": [
    "### Model Selection and Machine Learning\n",
    "\n",
    "> The practical work and results are carried out in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c040989-f44b-4db7-83f5-361c4e682169",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a copy of the original dataset\n",
    "\n",
    "data_ = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7d5464-509d-489b-b501-171e879d2765",
   "metadata": {},
   "source": [
    "#### Unsupervised Learning\n",
    "> Model 1: k-nearest neighbors (KNN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b224c78-fa33-4a0f-9ac1-9141123b4912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to categorize the price feature into:\n",
    "# High price ($1,500,000 and above); Medium price ($between $500,000 and $1,499,999); Low price (Less than $500,000)\n",
    "\n",
    "def price_category(price):\n",
    "    if price >= 1500000:\n",
    "        return 2\n",
    "    elif 500000 <= price < 1500000:\n",
    "        return 1\n",
    "    elif price < 500000:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "data_['price_group'] = data_['price'].apply(price_category)\n",
    "plt.ticklabel_format(style='plain')\n",
    "data_.price_group.value_counts().sort_index().plot(kind='bar')\n",
    "\n",
    "# Add labels to the bars\n",
    "for i, value in enumerate(data_['price_group'].value_counts().sort_index()):\n",
    "    plt.annotate(str(value), xy=(i, value), ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Price Group')  # Label for x-axis\n",
    "plt.ylabel('Count')  # Label for y-axis\n",
    "plt.title('Count of Instances in Each Price Group')  # Plot title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a821850-b604-45c4-b8b3-a34dcf255201",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn_data = data_[['bath', 'bed' , 'acre_lot' , 'house_size' , 'prev_sold_enc','price_group']]\n",
    "knn_factor = math.sqrt(knn_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e772296c-6ae2-48f8-b47c-4bacc033e266",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = knn_data.price_group\n",
    "\n",
    "feature_columns = ['bath', 'bed' , 'acre_lot' , 'house_size' , 'prev_sold_enc']\n",
    "X = knn_data[feature_columns]\n",
    "\n",
    "\n",
    "scores = []\n",
    "for frac in [.1,.2,.3,.4,.5]:\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=frac, random_state = 42, stratify = y, shuffle=True)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=370)\n",
    "    knn.fit(X_train,y_train)\n",
    "\n",
    "    y_pred=knn.predict(X_test)\n",
    "    scores.append(metrics.accuracy_score(y_test,y_pred))\n",
    "    print(\"Accuracy of test data: \", metrics.accuracy_score(y_test,y_pred),'frac:', frac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9955074-7808-4677-b0e7-9b541387d3d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "> Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eb80bc-a501-4dc7-909d-e9796d48fc51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cf_matrix =confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%', cmap='Blues')\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ae466e-6cd5-483c-9c63-1989f911edcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KNN Classification Report\n",
    "\n",
    "target_names = ['low_price', 'med_price', 'high_price']\n",
    "print(classification_report(y_test,y_pred,target_names = target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e77855-28dd-41c2-893c-a3cfbc5281a0",
   "metadata": {},
   "source": [
    "> Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e14dc81-d52d-47f7-9503-74a04e393b51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature Normalization\n",
    "\n",
    "# Min-Max normalization using MinMaxScaler\n",
    "data_['bed'] = MinMaxScaler().fit_transform(data_['bed'].values.reshape(len(data_), 1))\n",
    "data_['bath'] = MinMaxScaler().fit_transform(data_['bath'].values.reshape(len(data_), 1))\n",
    "data_['acre_lot'] = MinMaxScaler().fit_transform(data_['acre_lot'].values.reshape(len(data_), 1))\n",
    "\n",
    "\n",
    "# Z-score normalization (Standardization) using StandardScaler\n",
    "data_ = data.copy()\n",
    "data_['house_size'] = StandardScaler().fit_transform(data_['house_size'].values.reshape(len(data_), 1))\n",
    "data_['price'] = StandardScaler().fit_transform(data_['price'].values.reshape(len(data_), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4a7bd1-f6d2-455e-bbe1-322d4a37e6b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One-Hot Encoding for the 'state' and 'status' features\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False).set_output(transform='pandas')\n",
    "encoder_transform = encoder.fit_transform(data_[['status', 'state']])\n",
    "data_ = pd.concat([data_,encoder_transform], axis=1).drop(columns=['status', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f3fb28-21e6-4caa-b264-b0befc754cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split dataset into training and test sets\n",
    "# Split into training-test sets with ration 80:20\n",
    "# shuffle data to ensure no embedded pattern is retained\n",
    "# Set random_state to ensure same sets of training and test data are generated each time data is loaded\n",
    "\n",
    "train_data, test_data = train_test_split(data_, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "X = data_.drop('price', axis = 1)\n",
    "y = data_['price']\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8f819f-80b8-446b-b492-0d1f3a90f519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Shape of training and test datasets.\n",
    "# Also included is the price of training and test data for code test purpose \n",
    "# Result should be same each time data is loaded and below code is run\n",
    "\n",
    "print(f'The training data has {train_data.shape[0]} rows and {train_data.shape[1]} features\\n')\n",
    "print('*'*50)\n",
    "print(f'The test data has {test_data.shape[0]} rows and {test_data.shape[1]} features\\n')\n",
    "print('*'*50)\n",
    "print(f'Sum of price of training data is ${train_data.price.sum():,}\\n')\n",
    "print('*'*50)\n",
    "print(f'Sum of price of test data is ${test_data.price.sum():,}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b907c3ac-e65d-4406-98a5-316b4fba96c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Target Encoding for the 'city' feature\n",
    "encoder_target = ce.TargetEncoder(return_df=True)\n",
    "X_train_loo = encoder_target.fit_transform(train_x[['city']], train_y)\n",
    "train_x = pd.concat([train_x.drop('city', axis = 1),X_train_loo], axis=1)\n",
    "\n",
    "X_test_loo = encoder_target.fit_transform(test_x[['city']], test_y)\n",
    "test_x = pd.concat([test_x.drop('city', axis = 1),X_test_loo], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b08b20-e99b-4452-b489-fc7f6a39906a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x = train_x.select_dtypes(exclude=['object'])\n",
    "test_x = test_x.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50142e6-4ac4-4763-b182-42fbca24034b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Supervised Learning (SL)\n",
    "> SL Model 1: DecisionTreeRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dee89f-b4e6-4520-b0b0-bd109d137ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create the decision tree model\n",
    "model_DT = DecisionTreeRegressor(max_depth=5)\n",
    "\n",
    "# fit the model to the training set\n",
    "model_DT.fit(train_x, train_y)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model_DT.predict(test_x)\n",
    "\n",
    "# scores\n",
    "mse_DT = mean_squared_error(test_y, y_pred)\n",
    "rmse_DT = mean_squared_error(test_y, y_pred, squared=False)\n",
    "mae_DT = mean_absolute_error(test_y, y_pred)\n",
    "r2_DT = r2_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97982024-a3a0-41e6-b587-bfec711e8a6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "> SL Model 2: GradientBoostingRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dabdb8-576e-40a9-9d2f-f9d4c177c9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the GradientBoostingRegressor model\n",
    "model_GD = GradientBoostingRegressor(learning_rate=0.05,\n",
    "    n_estimators=150,\n",
    "    max_depth=3,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=1)\n",
    "\n",
    "# fit the model to the training set\n",
    "model_GD.fit(train_x, train_y)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model_GD.predict(test_x)\n",
    "\n",
    "# scores\n",
    "mse_GD = mean_squared_error(test_y, y_pred)\n",
    "rmse_GD = mean_squared_error(test_y, y_pred, squared=False)\n",
    "mae_GD = mean_absolute_error(test_y, y_pred)\n",
    "r2_GD = r2_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f97fa20-abbc-43bc-ac72-6c58bcc08291",
   "metadata": {},
   "source": [
    "> SL Model 3: LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5682cc3c-6477-4153-ab50-0381534ab9bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create the LinearRegression model\n",
    "model_LR = LinearRegression()\n",
    "\n",
    "# fit the model to the training set\n",
    "model_LR.fit(train_x, train_y)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model_LR.predict(test_x)\n",
    "\n",
    "# Scores\n",
    "mse_LR = mean_squared_error(test_y, y_pred)\n",
    "rmse_LR = mean_squared_error(test_y, y_pred, squared=False)\n",
    "mae_LR = mean_absolute_error(test_y, y_pred)\n",
    "r2_LR = r2_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc200e5b-6ef6-4040-ad46-8b42b00c9a42",
   "metadata": {},
   "source": [
    "> SL Model 4: Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9b09dd-46f9-4453-8e81-719ca452d64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the Lasso model\n",
    "model_Lasso = Lasso()\n",
    "\n",
    "# fit the model to the training set\n",
    "model_Lasso.fit(train_x, train_y)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model_Lasso.predict(test_x)\n",
    "\n",
    "# scores\n",
    "mse_Lasso = mean_squared_error(test_y, y_pred)\n",
    "rmse_Lasso = mean_squared_error(test_y, y_pred, squared=False)\n",
    "mae_Lasso = mean_absolute_error(test_y, y_pred)\n",
    "r2_Lasso = r2_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5811c3-f772-49a7-aa0f-a9f7c7ed1bc9",
   "metadata": {},
   "source": [
    "> SL Model 5: Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58197f2-b040-45b0-90b0-ac69946c1a09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create the ridge model\n",
    "ridge_model = Ridge()\n",
    "\n",
    "# fit the model to the training set\n",
    "ridge_model.fit(train_x, train_y)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = ridge_model.predict(test_x)\n",
    "\n",
    "# scores\n",
    "mse_Rg = mean_squared_error(test_y, y_pred)\n",
    "rmse_Rg = mean_squared_error(test_y, y_pred, squared=False)\n",
    "mae_Rg = mean_absolute_error(test_y, y_pred)\n",
    "r2_Rg = r2_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b754813-2026-4acc-8de3-cc19efc19fab",
   "metadata": {},
   "source": [
    "> SL Model 6: Ridge with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e3226b-1696-4e96-8678-92c4d1a66bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the ridge cross-validation model\n",
    "ridge_cv_model = RidgeCV(alphas=(1.38), scoring='neg_mean_absolute_error')\n",
    "\n",
    "# fit the model to the training set\n",
    "ridge_cv_model.fit(train_x, train_y)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = ridge_cv_model.predict(test_x)\n",
    "\n",
    "# scores\n",
    "mse_R = mean_squared_error(test_y, y_pred)\n",
    "rmse_R = mean_squared_error(test_y, y_pred, squared=False)\n",
    "mae_R = mean_absolute_error(test_y, y_pred)\n",
    "r2_R = r2_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aa9873-ff62-4699-96bc-2cb58a332ee4",
   "metadata": {},
   "source": [
    "> SL Model 7: ElasticNet Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233f0173-b09e-4fb1-bcb7-a4be770ef940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the ElasticNetCV model\n",
    "elastic_model = ElasticNetCV(l1_ratio=[0.01], tol=0.01)\n",
    "\n",
    "# fit the model to the training set\n",
    "elastic_model.fit(train_x, train_y)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = elastic_model.predict(test_x)\n",
    "\n",
    "# scores\n",
    "mse_E = mean_squared_error(test_y, y_pred)\n",
    "rmse_E = mean_squared_error(test_y, y_pred, squared=False)\n",
    "mae_E = mean_absolute_error(test_y, y_pred)\n",
    "r2_E = r2_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2c4487-e38a-4489-958e-d36dbaf751e2",
   "metadata": {},
   "source": [
    "> SL Model 8: KNeighborsRegressor Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e041590d-d59e-4301-9502-b1e7152e07a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the KNeighborsRegressor model\n",
    "model_KNN = KNeighborsRegressor(n_neighbors=10)\n",
    "\n",
    "# fit the model to the training set\n",
    "model_KNN.fit(train_x, train_y)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model_KNN.predict(test_x)\n",
    "\n",
    "# Scores\n",
    "mse_KNN = mean_squared_error(test_y, y_pred)\n",
    "rmse_KNN = mean_squared_error(test_y, y_pred, squared=False)\n",
    "mae_KNN = mean_absolute_error(test_y, y_pred)\n",
    "r2_KNN = r2_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dfa13f-60e8-4bcf-b102-2d81f0e4d936",
   "metadata": {},
   "source": [
    "> Supervised Learning Models Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddbac27-fe2a-43db-9b90-6606db56d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'Linear Regression': {'MSE': mse_LR, 'RMSE': rmse_LR, 'MAE': mae_LR, 'R^2': r2_LR},\n",
    "    'Decision Tree': {'MSE': mse_DT, 'RMSE': rmse_DT, 'MAE': mae_DT, 'R^2': r2_DT},\n",
    "    'K-Nearest Neighbors': {'MSE': mse_KNN, 'RMSE': rmse_KNN, 'MAE': mae_KNN, 'R^2': r2_KNN},\n",
    "    'Gradient Boosting': {'MSE': mse_GD, 'RMSE': rmse_GD, 'MAE': mae_GD, 'R^2': r2_GD},\n",
    "    'Lasso': {'MSE': mse_Lasso, 'RMSE': rmse_Lasso, 'MAE': mae_Lasso, 'R^2': r2_Lasso},\n",
    "    'Ridge': {'MSE': mse_Rg, 'RMSE': rmse_Rg, 'MAE': mae_Rg, 'R^2': r2_Rg},\n",
    "    'Ridge CV': {'MSE': mse_R, 'RMSE': rmse_R, 'MAE': mae_R, 'R^2': r2_R},\n",
    "    'ElasticNet CV': {'MSE': mse_E, 'RMSE': rmse_E, 'MAE': mae_E, 'R^2': r2_E}\n",
    "}\n",
    "\n",
    "\n",
    "result_data = pd.DataFrame.from_dict(results, orient='index')\n",
    "result_data = result_data.applymap(lambda x: f'{x:.2f}')\n",
    "\n",
    "print('Performance Measures of all Models')\n",
    "print('*'*50)\n",
    "result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd5276-b8c0-4c2a-b196-e6b5030f3710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Models Comparison\n",
    "\n",
    "model_names = ['Linear Regression', 'Decision Tree', 'K-Nearest Neighbors', 'Gradient Boosting', 'Ridge', 'Ridge CV', 'ElasticNet CV' ]\n",
    "scores = [r2_LR, r2_DT, r2_KNN, r2_GD, r2_Rg, r2_R, r2_E]\n",
    "plt.figure(figsize=(15, 5))\n",
    "#plt.xlim(2, 8)\n",
    "#plt.yticks([0.4, 0.45, 0.5, 0.55, 0.6, 0.65])\n",
    "plt.ylim(0, 1)\n",
    "colors = ['blue', 'green', 'red', 'purple', 'cyan', 'grey', 'yellow', 'purple']\n",
    "plt.bar(model_names, scores, width=0.8, color=colors)\n",
    "#plt.hist(result_data)\n",
    "plt.title('Comparison of the Model Scores')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Score')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda39e1f-c642-4eba-9bd1-694af5189a1a",
   "metadata": {},
   "source": [
    "> Regression Coefficient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d405e4d0-f78f-46f9-bc6b-683596a6e4f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Regression Coefficients\n",
    "\n",
    "train_x_cor = train_x[['bed', 'bath', 'acre_lot', 'house_size', 'prev_sold_enc', 'city']]\n",
    "test_x_cor = test_x[['bed', 'bath', 'acre_lot', 'house_size', 'prev_sold_enc', 'city']]\n",
    "\n",
    "# Fit linear regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(train_x_cor, train_y)\n",
    "\n",
    "# Fit ridge regression model\n",
    "ridge_model = Ridge(alpha=1.0)  # You can adjust the regularization strength (alpha) if needed\n",
    "ridge_model.fit(train_x_cor, train_y)\n",
    "\n",
    "# Fit Lasso regression model\n",
    "lasso_model = Lasso(alpha=1.0)  # You can adjust the regularization strength (alpha) if needed\n",
    "lasso_model.fit(train_x_cor, train_y)\n",
    "\n",
    "\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': train_x_cor.columns,\n",
    "    'Linear Regression Coefficient': lr_model.coef_,\n",
    "    'Ridge Regression Coefficient': ridge_model.coef_,\n",
    "    'Lasso Regression Coefficient': lasso_model.coef_})\n",
    "\n",
    "\n",
    "## Use columns that have not been normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fc76f1-f6d5-40b7-8751-7e92843f64a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Regression Coefficients\n",
    "print('Regression Coefficients')\n",
    "print('*'*50)\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0541d602-79bd-4e5b-95ce-8152ecb61015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X1 = train_x[['bed', 'bath', 'acre_lot', 'house_size', 'prev_sold_enc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4d8189-7532-44f3-a150-25091a38d5f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Classifier Acuracy Score\n",
    "X2 = data_[['bed', 'bath', 'acre_lot', 'house_size', 'prev_sold_enc']]\n",
    "y2 = data_['price']\n",
    "# Discretize the target variable into bins (classification problem)\n",
    "# You can adjust the number of bins and strategy as needed\n",
    "discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "y2_discretized = discretizer.fit_transform(y2.values.reshape(-1, 1))\n",
    "\n",
    "train_x2, test_x2, train_y2, test_y2 = train_test_split(X2, y2_discretized, test_size = 0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "\n",
    "\n",
    "# Initialize and train a logistic regression classifier\n",
    "classifier = LogisticRegression(max_iter=1000)  # Increase max_iter if needed\n",
    "classifier.fit(train_x2, train_y2.ravel())  # Note: ravel() converts y1_discretized to 1D array\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = classifier.predict(test_x2)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_y2, y_pred)\n",
    "print(\"Classifier Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8b768d-1b72-408b-8cf2-4cb0de9517da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract coefficients and feature names\n",
    "coefficients = classifier.coef_[0]\n",
    "feature_names = X2.columns\n",
    "\n",
    "# Print feature contributions to accuracy\n",
    "for feature, coefficient in zip(feature_names, coefficients):\n",
    "    print(f\"Feature: {feature}, Coefficient: {coefficient}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
